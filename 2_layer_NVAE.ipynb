{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2 layer NVAE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Qa1C5DhKRK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "2dd7d893-841b-4a80-b512-2389564a903a"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Aug  8 20:15:33 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8    12W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXv8jEgLhP8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0mrK9zbhYRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGImWn1QT3ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class depthwise_separable_conv(nn.Module):\n",
        "    def __init__(self, nin, kernels_per_layer, nout):\n",
        "        super(depthwise_separable_conv, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(nin, nin * kernels_per_layer, kernel_size=5, padding=2, groups=nin)\n",
        "        self.pointwise = nn.Conv2d(nin * kernels_per_layer, nout, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.depthwise(x)\n",
        "        out = self.pointwise(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAByRF1lVYYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def swish(x):\n",
        "    return x * torch.sigmoid(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRIKW4u_Y9Qj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ChannelSELayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Re-implementation of Squeeze-and-Excitation (SE) block described in:\n",
        "        *Hu et al., Squeeze-and-Excitation Networks, arXiv:1709.01507*\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_channels, reduction_ratio=2):\n",
        "        \"\"\"\n",
        "        :param num_channels: No of input channels\n",
        "        :param reduction_ratio: By how much should the num_channels should be reduced\n",
        "        \"\"\"\n",
        "        super(ChannelSELayer, self).__init__()\n",
        "        num_channels_reduced = num_channels // reduction_ratio\n",
        "        self.reduction_ratio = reduction_ratio\n",
        "        self.fc1 = nn.Linear(num_channels, num_channels_reduced, bias=True)\n",
        "        self.fc2 = nn.Linear(num_channels_reduced, num_channels, bias=True)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        \"\"\"\n",
        "        :param input_tensor: X, shape = (batch_size, num_channels, H, W)\n",
        "        :return: output tensor\n",
        "        \"\"\"\n",
        "        batch_size, num_channels, H, W = input_tensor.size()\n",
        "        # Average along each channel\n",
        "        squeeze_tensor = input_tensor.view(batch_size, num_channels, -1).mean(dim=2)\n",
        "\n",
        "        # channel excitation\n",
        "        fc_out_1 = self.relu(self.fc1(squeeze_tensor))\n",
        "        fc_out_2 = self.sigmoid(self.fc2(fc_out_1))\n",
        "\n",
        "        a, b = squeeze_tensor.size()\n",
        "        output_tensor = torch.mul(input_tensor, fc_out_2.view(a, b, 1, 1))\n",
        "        return output_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSK2fT3yhZzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class dec_res(nn.Module):\n",
        "  def __init__(self,in_channel):\n",
        "    super(dec_res,self).__init__()\n",
        "    self.bn1 = nn.BatchNorm2d(in_channel)\n",
        "    self.c1 = nn.Conv2d(in_channels=in_channel,out_channels=2*in_channel,kernel_size=1,stride=1,padding=0)\n",
        "    self.bn2 = nn.BatchNorm2d(2*in_channel)\n",
        "    self.dc1 = depthwise_separable_conv(nin=2*in_channel,kernels_per_layer=3,nout=2*in_channel)\n",
        "    self.bn3 = nn.BatchNorm2d(2*in_channel)\n",
        "    self.c2 = nn.Conv2d(in_channels=2*in_channel,out_channels=in_channel,kernel_size=1,stride=1,padding=0)\n",
        "    self.bn4 = nn.BatchNorm2d(in_channel)\n",
        "    self.SE = ChannelSELayer(in_channel)\n",
        "  def forward(self,x1):\n",
        "    x = self.c1(self.bn1(x1))\n",
        "    x = swish(self.bn2(x))\n",
        "    x = self.dc1(x)\n",
        "    x = swish(self.bn3(x))\n",
        "    x = self.bn4(self.c2(x))\n",
        "    x = self.SE(x)\n",
        "    return x+x1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLd9QILwaLib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class enc_res(nn.Module):\n",
        "  def __init__(self,in_channel):\n",
        "    super(enc_res,self).__init__()\n",
        "    self.bn1 = nn.BatchNorm2d(in_channel)\n",
        "    self.c1 = nn.Conv2d(in_channels=in_channel,out_channels=2*in_channel,kernel_size=3,stride=1,padding=1)\n",
        "    self.bn2 = nn.BatchNorm2d(2*in_channel)\n",
        "    self.c2 = nn.Conv2d(in_channels=2*in_channel,out_channels=in_channel,kernel_size=3,stride=1,padding=1)\n",
        "    self.bn3 = nn.BatchNorm2d(in_channel)\n",
        "    self.SE = ChannelSELayer(in_channel)\n",
        "  def forward(self,x1):\n",
        "    x = self.c1(swish(self.bn1(x1)))\n",
        "    x = self.c2(swish(self.bn2(x)))\n",
        "    x = self.SE(x)\n",
        "    return x+x1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wxrN2-Db5ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NVAE(nn.Module):\n",
        "  def __init__(self,start_channel,original_dim):\n",
        "    super(NVAE,self).__init__()\n",
        "    self.original_dim = original_dim\n",
        "    self.conv1 = nn.Conv2d(in_channels=start_channel,out_channels=8,kernel_size=3,stride=1,padding=1)\n",
        "    self.encblock1 = enc_res(8)\n",
        "    self.dsconv1 = nn.Conv2d(in_channels=8,out_channels=8,kernel_size=2,stride=2,padding=0)\n",
        "    self.encblock2 = enc_res(8)\n",
        "    self.dsconv2 = nn.Conv2d(in_channels=8,out_channels=8,kernel_size=2,stride=2,padding=0)\n",
        "\n",
        "    self.qmu1 = nn.Linear(original_dim*original_dim*2,original_dim*original_dim*2)\n",
        "    self.qvar1 = nn.Linear(original_dim*original_dim*2,original_dim*original_dim*2)\n",
        "    \n",
        "    self.qmu0 = nn.Linear(original_dim*original_dim//2,original_dim*original_dim//2)\n",
        "    self.qvar0 = nn.Linear(original_dim*original_dim//2,original_dim*original_dim//2)\n",
        "\n",
        "    self.pmu1 = nn.Linear(original_dim*original_dim*2,original_dim*original_dim*2)\n",
        "    self.pvar1 = nn.Linear(original_dim*original_dim*2,original_dim*original_dim*2)\n",
        "\n",
        "    self.decblock1 = dec_res(8)\n",
        "    self.usconv1 = nn.ConvTranspose2d(in_channels=8,out_channels=8,kernel_size=2,stride=2,padding=0)\n",
        "    self.decblock2 = dec_res(16)\n",
        "    self.usconv2 = nn.ConvTranspose2d(in_channels=16,out_channels=16,kernel_size=2,stride=2,padding=0)\n",
        "    self.decblock3 = dec_res(16)\n",
        "    self.finconv = nn.Conv2d(in_channels=16,out_channels=start_channel,kernel_size=3,stride=1,padding=1)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    z1 = self.dsconv1(self.encblock1(self.conv1(x)))\n",
        "    z0 = self.dsconv2(self.encblock2(z1))\n",
        "\n",
        "    qmu0 = self.qmu0(z0.reshape(z0.shape[0],self.original_dim*self.original_dim//2))\n",
        "    qvar0 = self.qvar0(z0.reshape(z0.shape[0],self.original_dim*self.original_dim//2))\n",
        "\n",
        "    qmu1 = self.qmu1(z1.reshape(z1.shape[0],self.original_dim*self.original_dim*2))\n",
        "    qvar1 = self.qvar1(z1.reshape(z1.shape[0],self.original_dim*self.original_dim*2))\n",
        "\n",
        "    stdvar0 = qvar0.mul(0.5).exp_()\n",
        "    stdvar1 = qvar1.mul(0.5).exp_()\n",
        "\n",
        "    e0 = torch.randn(qmu0.shape).to(device)\n",
        "    ez0 = qmu0+e0*stdvar0\n",
        "    ez0 = ez0.reshape(ez0.shape[0],8,self.original_dim//4,self.original_dim//4)\n",
        "    ez1 = self.usconv1(self.decblock1(ez0))\n",
        "\n",
        "    pmu1 = self.pmu1(ez1.reshape(ez1.shape[0],self.original_dim*self.original_dim*2))\n",
        "    pvar1 = self.pvar1(ez1.reshape(ez1.shape[0],self.original_dim*self.original_dim*2))\n",
        "\n",
        "    pstdvar1 = pvar1.mul(0.5).exp_()\n",
        "\n",
        "    e2 = torch.randn(qmu1.shape).to(device)\n",
        "    ez2 = pmu1+qmu1 + e2*pstdvar1*stdvar1\n",
        "    ez2 = ez2.reshape(ez2.shape[0],8,self.original_dim//2,self.original_dim//2)\n",
        "    \n",
        "    final = torch.cat((ez1,ez2),1)\n",
        "\n",
        "    recons = nn.Sigmoid()(self.finconv(self.decblock3(self.usconv2(self.decblock2(final)))))\n",
        "\n",
        "    return qmu0,qvar0,qmu1,qvar1,pmu1,pvar1,recons\n",
        "\n",
        "  def sample(self,bs):\n",
        "    e = torch.randn([bs,8,self.original_dim//4,self.original_dim//4]).to(device)\n",
        "    ez1 = self.usconv1(self.decblock1(e))\n",
        "\n",
        "    pmu1 = self.pmu1(ez1.reshape(ez1.shape[0],self.original_dim*self.original_dim*2))\n",
        "    pvar1 = self.pvar1(ez1.reshape(ez1.shape[0],self.original_dim*self.original_dim*2))\n",
        "\n",
        "    stdvar1 = pvar1.mul(0.5).exp_()\n",
        "\n",
        "    e1 = torch.randn([ez1.shape[0],self.original_dim*self.original_dim*2]).to(device)\n",
        "    e1 = pmu1 + e1*stdvar1\n",
        "    e1 = e1.reshape(e1.shape[0],8,self.original_dim//2,self.original_dim//2)\n",
        "    recons = nn.Sigmoid()(self.finconv(self.decblock3(self.usconv2(self.decblock2(torch.cat((ez1,e1),1))))))\n",
        "\n",
        "    return recons\n",
        "\n",
        "  def loss(self,x):\n",
        "    qmu0,qvar0,qmu1,qvar1,pmu1,pvar1,recons = self.forward(x)\n",
        "    klz0 = 0.5*torch.sum(torch.square(qmu0)+qvar0.exp()-qvar0-1)/x.shape[0]\n",
        "    klz1 = 0.5*torch.sum(torch.square(qmu1)/pvar1.exp()+qvar1.exp()-qvar1-1)\n",
        "    reconsloss = nn.BCELoss()(recons,x)\n",
        "    return klz0,klz1,reconsloss\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9efDihByrV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70Ihzmehy3gx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSqNRvcXy4s7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mnist data\n",
        "train_dataset = torchvision.datasets.MNIST(root='data/mnist',\n",
        "                                           train=True, \n",
        "                                           transform=transform,\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='data/mnist',\n",
        "                                          train=False, \n",
        "                                          transform=transform)\n",
        "#put into batches\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wALKs6y1y8ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = NVAE(1,28).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TfgpWKZzIYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optim = torch.optim.Adamax(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kChCMWXezYa6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv0R5WJ3tSuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwrnwDMUzbTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "4fbb43a8-31f7-4840-a343-058c35c00611"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    minloss = 1\n",
        "    running_kl0_loss=0\n",
        "    running_recons_loss=0\n",
        "    running_kl1_loss=0\n",
        "    num_images=0\n",
        "    for i,(img,label) in enumerate(train_loader):\n",
        "      img = img.to(device)\n",
        "      # label=label.to(device)\n",
        "      optim.zero_grad()\n",
        "      klz0,klz1,recons = model.loss(img)\n",
        "      loss=recons+epoch*0.001*klz0+epoch*0.0001*klz1\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "      running_kl0_loss = running_kl0_loss + klz0.item()*len(img)\n",
        "      running_kl1_loss = running_kl1_loss + klz1.item()*len(img)\n",
        "      running_recons_loss = running_recons_loss + recons.item()*len(img)\n",
        "\n",
        "      num_images= num_images+len(img)\n",
        "    print('epoch: '+str(epoch)+' kl0_loss: '+str(running_kl0_loss/num_images)+' recons_loss: '+str(running_recons_loss/num_images)+' kl1_loss: '+str(running_kl1_loss/num_images))\n",
        "    imgs = model.sample(64).cpu().detach().reshape(64,28,28)\n",
        "    plt.gray()\n",
        "    fig = plt.figure(figsize=(8., 8.))\n",
        "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                    nrows_ncols=(8, 8),  # creates 2x2 grid of axes\n",
        "                    axes_pad=0.05  # pad between axes in inch.\n",
        "                    )\n",
        "\n",
        "    for ax, im in zip(grid, imgs):\n",
        "        # Iterating over the grid returns the Axes.\n",
        "        ax.imshow(im)\n",
        "    plt.savefig(str(epoch)+\".png\")\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 kl0_loss: 606.4141020177206 recons_loss: 0.08246776552001635 kl1_loss: 5356494.420431966\n",
            "epoch: 1 kl0_loss: 103.98859626871744 recons_loss: 0.18555358707904815 kl1_loss: 27655.114556966146\n",
            "epoch: 2 kl0_loss: 35.97397475382487 recons_loss: 0.20749857869942984 kl1_loss: 397.4461079264323\n",
            "epoch: 3 kl0_loss: 15.648203428141276 recons_loss: 0.20467347184816997 kl1_loss: 132.21166833089194\n",
            "epoch: 4 kl0_loss: 9.369819069417318 recons_loss: 0.1984669742425283 kl1_loss: 48.45297568359375\n",
            "epoch: 5 kl0_loss: 7.066677468363444 recons_loss: 0.19788822547594706 kl1_loss: 16.822802369689942\n",
            "epoch: 6 kl0_loss: 5.902504239400228 recons_loss: 0.19954941023190817 kl1_loss: 6.5516442260742185\n",
            "epoch: 7 kl0_loss: 5.115420579020182 recons_loss: 0.20067655108769736 kl1_loss: 3.0555039043426513\n",
            "epoch: 8 kl0_loss: 4.619134643554688 recons_loss: 0.197725900888443 kl1_loss: 1.7534462911923727\n",
            "epoch: 9 kl0_loss: 4.31119142074585 recons_loss: 0.19328678325017293 kl1_loss: 1.002563635778427\n",
            "epoch: 10 kl0_loss: 4.132419648234049 recons_loss: 0.19005021042029063 kl1_loss: 0.5720913254261016\n",
            "epoch: 11 kl0_loss: 3.9559184013366697 recons_loss: 0.1893531315088272 kl1_loss: 0.38830435110727946\n",
            "epoch: 12 kl0_loss: 3.6730920962015787 recons_loss: 0.1913944269100825 kl1_loss: 0.257180270020167\n",
            "epoch: 13 kl0_loss: 3.377283206939697 recons_loss: 0.19425354584852855 kl1_loss: 0.19054281061490377\n",
            "epoch: 14 kl0_loss: 3.0857354901631675 recons_loss: 0.19755690948168436 kl1_loss: 0.14716289758682252\n",
            "epoch: 15 kl0_loss: 2.828593865966797 recons_loss: 0.20089894302686057 kl1_loss: 0.11742404181162516\n",
            "epoch: 16 kl0_loss: 2.606420080947876 recons_loss: 0.20412242434819539 kl1_loss: 0.0998434814453125\n",
            "epoch: 17 kl0_loss: 2.3702501251220705 recons_loss: 0.20763317405382792 kl1_loss: 0.08098695723215739\n",
            "epoch: 18 kl0_loss: 2.159138159561157 recons_loss: 0.21126369598706563 kl1_loss: 0.06749423338572184\n",
            "epoch: 19 kl0_loss: 1.9697257671991983 recons_loss: 0.21458210515181222 kl1_loss: 0.056395024394989016\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 20 kl0_loss: 1.7575090525945027 recons_loss: 0.21876556200186412 kl1_loss: 0.04653615934054057\n",
            "epoch: 21 kl0_loss: 1.5570258632659912 recons_loss: 0.22268498921394347 kl1_loss: 0.0396785405476888\n",
            "epoch: 22 kl0_loss: 1.3601469254175822 recons_loss: 0.22699188867410025 kl1_loss: 0.03254029804865519\n",
            "epoch: 23 kl0_loss: 1.1691280216217041 recons_loss: 0.23126601158777874 kl1_loss: 0.02503287035624186\n",
            "epoch: 24 kl0_loss: 0.9971819259961446 recons_loss: 0.2348970758597056 kl1_loss: 0.021144128227233886\n",
            "epoch: 25 kl0_loss: 0.8291180100123088 recons_loss: 0.23902759352525074 kl1_loss: 0.016420564317703248\n",
            "epoch: 26 kl0_loss: 0.6568803822835286 recons_loss: 0.24345691878000894 kl1_loss: 0.01354682772954305\n",
            "epoch: 27 kl0_loss: 0.5299254002253214 recons_loss: 0.24654099411964417 kl1_loss: 0.01146696524620056\n",
            "epoch: 28 kl0_loss: 0.43261469926834106 recons_loss: 0.2492763815800349 kl1_loss: 0.009007540734608969\n",
            "epoch: 29 kl0_loss: 0.3427351002852122 recons_loss: 0.2516372921625773 kl1_loss: 0.0076933453718821205\n",
            "epoch: 30 kl0_loss: 0.28523227502504983 recons_loss: 0.2535159907499949 kl1_loss: 0.006370060205459595\n",
            "epoch: 31 kl0_loss: 0.22992042937278748 recons_loss: 0.2549317709604899 kl1_loss: 0.005380495707194011\n",
            "epoch: 32 kl0_loss: 0.19142505009174346 recons_loss: 0.25611110626856487 kl1_loss: 0.0046370019912719725\n",
            "epoch: 33 kl0_loss: 0.16055619466702142 recons_loss: 0.25724373655319216 kl1_loss: 0.0037070334911346436\n",
            "epoch: 34 kl0_loss: 0.1352140294512113 recons_loss: 0.25800682676633196 kl1_loss: 0.0030073412736256917\n",
            "epoch: 35 kl0_loss: 0.10839028403361638 recons_loss: 0.2589515482902527 kl1_loss: 0.0024130579948425292\n",
            "epoch: 36 kl0_loss: 0.08792872133652369 recons_loss: 0.2597006818612417 kl1_loss: 0.0019266786575317383\n",
            "epoch: 37 kl0_loss: 0.08023004442453384 recons_loss: 0.25983840271631875 kl1_loss: 0.0015059247811635334\n",
            "epoch: 38 kl0_loss: 0.06504717428882917 recons_loss: 0.2604132067839305 kl1_loss: 0.0013676724910736083\n",
            "epoch: 39 kl0_loss: 0.044072804554303485 recons_loss: 0.26119349540074666 kl1_loss: 0.0012322275161743164\n",
            "epoch: 40 kl0_loss: 0.031043682791789373 recons_loss: 0.26174673940340676 kl1_loss: 0.0006729445139567057\n",
            "epoch: 41 kl0_loss: 0.011118782258530458 recons_loss: 0.2625766527334849 kl1_loss: 0.0008687736829121908\n",
            "epoch: 42 kl0_loss: 0.01020707905292511 recons_loss: 0.26254374332427977 kl1_loss: 0.00027893454233805337\n",
            "epoch: 43 kl0_loss: 0.003944423676033815 recons_loss: 0.2627823225180308 kl1_loss: 0.0010341333707173665\n",
            "epoch: 44 kl0_loss: 0.0023125527853767075 recons_loss: 0.26285736045837405 kl1_loss: -6.421395937601726e-05\n",
            "epoch: 45 kl0_loss: 0.0010094001988569896 recons_loss: 0.2629272048632304 kl1_loss: 0.001959748315811157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLaxWbCh0E5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs = model.sample(64).cpu().detach().reshape(64,28,28)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZWGz6Kg2is1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14K4PP692gLc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.gray()\n",
        "fig = plt.figure(figsize=(8., 8.))\n",
        "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
        "                 nrows_ncols=(8, 8),  # creates 2x2 grid of axes\n",
        "                 axes_pad=0.05  # pad between axes in inch.\n",
        "                 )\n",
        "\n",
        "for ax, im in zip(grid, imgs):\n",
        "    # Iterating over the grid returns the Axes.\n",
        "    ax.imshow(im)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77sDExJQ2nd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}